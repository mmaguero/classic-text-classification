{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# codetest4_seedtag\n",
    "\n",
    "- Author: mmaguero\n",
    "- Date: 2020-12-12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas sklearn click nltk XGBoost joblib spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m spacy download en_core_web_md"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from preprocessing import load_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3859 entries, 0 to 3858\n",
      "Data columns (total 3 columns):\n",
      "id          3859 non-null object\n",
      "category    3859 non-null object\n",
      "text        3859 non-null object\n",
      "dtypes: object(3)\n",
      "memory usage: 90.6+ KB\n"
     ]
    }
   ],
   "source": [
    "mydf = load_data(path=\"dataset\", extension=\"\",output=\"data/corpus.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es más conveniente tenerlos así: id, categoría, texto. Viene bien para cualquier análisis que se quiera hacer y para la pipeline de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3859\r\n"
     ]
    }
   ],
   "source": [
    "# check files\n",
    "! ls dataset/*/* | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El número de files coinicide con el número de rows (text non null) en el frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>178962</td>\n",
       "      <td>intelligence</td>\n",
       "      <td>b\"n article &lt;mwalker-160493090617@mwalker.npd....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1951</th>\n",
       "      <td>102701</td>\n",
       "      <td>politics</td>\n",
       "      <td>b\"ticle-I.D.: alleg.1993Apr6.210157.2758\\n\\nIn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2710</th>\n",
       "      <td>54608</td>\n",
       "      <td>weapons</td>\n",
       "      <td>b\"n &lt;C5sv4r.HFA@news.cso.uiuc.edu&gt; irvine@uxh....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1451</th>\n",
       "      <td>60253</td>\n",
       "      <td>exploration</td>\n",
       "      <td>b'ticle-I.D.: topaz.STEINLY.93Apr6170313\\n\\nIn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2247</th>\n",
       "      <td>104342</td>\n",
       "      <td>politics</td>\n",
       "      <td>b'n article 120399@netnews.upenn.edu, sepinwal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1673</th>\n",
       "      <td>104689</td>\n",
       "      <td>politics</td>\n",
       "      <td>b' had heard the rumors about LA, Cin, Hou, an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3267</th>\n",
       "      <td>38376</td>\n",
       "      <td>headhunters</td>\n",
       "      <td>b'\\nComputer Graphics Resource Listing : WEEKL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3456</th>\n",
       "      <td>53135</td>\n",
       "      <td>logistics</td>\n",
       "      <td>b'n article &lt;1qi156INNf9n@senator-bedfellow.MI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2284</th>\n",
       "      <td>54537</td>\n",
       "      <td>weapons</td>\n",
       "      <td>b\" predict that the outcome of the study of wh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3345</th>\n",
       "      <td>38651</td>\n",
       "      <td>headhunters</td>\n",
       "      <td>b're there any TIFF to anything programs out t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id      category                                               text\n",
       "55    178962  intelligence  b\"n article <mwalker-160493090617@mwalker.npd....\n",
       "1951  102701      politics  b\"ticle-I.D.: alleg.1993Apr6.210157.2758\\n\\nIn...\n",
       "2710   54608       weapons  b\"n <C5sv4r.HFA@news.cso.uiuc.edu> irvine@uxh....\n",
       "1451   60253   exploration  b'ticle-I.D.: topaz.STEINLY.93Apr6170313\\n\\nIn...\n",
       "2247  104342      politics  b'n article 120399@netnews.upenn.edu, sepinwal...\n",
       "1673  104689      politics  b' had heard the rumors about LA, Cin, Hou, an...\n",
       "3267   38376   headhunters  b'\\nComputer Graphics Resource Listing : WEEKL...\n",
       "3456   53135     logistics  b'n article <1qi156INNf9n@senator-bedfellow.MI...\n",
       "2284   54537       weapons  b\" predict that the outcome of the study of wh...\n",
       "3345   38651   headhunters  b're there any TIFF to anything programs out t..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see some samples\n",
    "mydf.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3571"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# simple lang identification: its have \"the\": https://en.wikipedia.org/wiki/The (most common word)\n",
    "mydf[\"the\"] = mydf.text.apply(lambda a: 1 if \"the\" in str(a).split() else 0)\n",
    "sum(mydf[\"the\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "703     b'n article <C5r66A.6rB@srgenprp.sr.hp.com> al...\n",
       "3059    b'C51Eyz.4Ix@optimla.aimla.com> <1993Apr6.1445...\n",
       "2985    b'oes anyone have a radon transform in C that ...\n",
       "865     b'ccording to a LoJack representative I saw re...\n",
       "2989    b'e have been using Iterated Systems compressi...\n",
       "2667    b\"n article <1qrn3aINN4rq@clem.handheld.com> j...\n",
       "553     b\"ou can be sure they wouldn't do it if it was...\n",
       "1148    b\" C-3's bird may be flaking out and expecting...\n",
       "2087    b\"ello All,\\n\\nI'd like to learn how to keep s...\n",
       "1766    b\"ticle-I.D.: agate.1ps77v$5dr\\n\\n\\n\\t     MLB...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mydf[mydf.the==0][\"text\"].sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...es un dataset en English"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For train and test:\n",
    "    - remove null texts\n",
    "    - spit data in 80/10/10 train/test/eval\n",
    "- For train and test: \n",
    "    - clean text:\n",
    "    - Experimento 1\n",
    "        - lowercase\n",
    "        - remove \"\\n\"\n",
    "    - Experimento 2 (add)\n",
    "        - clean: ignore_url=True, content_words=True, lemma=True, that is, URL out, only content words with lemma\n",
    "- Inference:\n",
    "    - the (best model) last experiment setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f0ddf948be0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "mydf['category'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parecen clases balanceadas, excepto logistics o intelligence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamos 6 modelos bien conocidos para clasificación (también para textos):\n",
    "- MNB, Multinomial Naive Bayes, probabilista simple y muy usado porque produce resultados tan buenos como otros modelos mas sofisticados\n",
    "- LogReg, Regresión Logística, multifuncional, así como MNB, simple :)! una red neuronal miniatura?\n",
    "- RFC, Random Forests, un ensemble de árboles! \n",
    "- SVC, Linear Support Vector Machine, busca la distancia en el hiperplano para clasificar y suele ser muy estable.\n",
    "- XGBoost, un ensemble y suelen funcionar bien con variables catégoricas y pocas clases. \n",
    "- KNN, K-Vecinos cercanos, cuando llega un nuevo texto, se toma su vector de características y se extraen los k textos más cercanos de nuestra base de datos. Después, se etiqueta el nuevo texto conforme a las categorías de sus vecinos. Idealmente, todos sus vecinos tendrán los mismas. Ya veremos...\n",
    "\n",
    "Todos los modelos, primero pasan por una pipeline, además del preprocesado:\n",
    "- CountVectorizer, una bolsa de palabras con sus frecuencias\n",
    "- Tf-idfVectorizer, transform, para responder a: how relevant a word is to a document in a collection of documents?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimento 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Pipeline_:\n",
    "\n",
    "`pipeline[name] = Pipeline([\n",
    "                ('vect', CountVectorizer(stop_words=stop_words,preprocessor=clean_text)),\n",
    "                ('tfidf', TfidfVectorizer()),\n",
    "                ('clf', model),\n",
    "            ], verbose=1)`\n",
    "            \n",
    "_Models params_:\n",
    "\n",
    "`models = {\"MNB\": MultinomialNB(fit_prior=True, class_prior=None),\n",
    "          \"SVC\":LinearSVC(),\n",
    "          \"LogReg\":LogisticRegression(solver='sag',n_jobs=-1),\n",
    "          \"XGB\":XGBClassifier(n_jobs=-1,eval_metric='merror'),\n",
    "          \"RFC\":RandomForestClassifier(n_jobs=-1),\n",
    "          \"KNN\":KNeighborsClassifier(n_neighbors=10,n_jobs=-1)} # slow, use 10 neighbors`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3859 entries, 0 to 3858\n",
      "Data columns (total 3 columns):\n",
      "id          3859 non-null object\n",
      "category    3859 non-null object\n",
      "text        3859 non-null object\n",
      "dtypes: object(3)\n",
      "memory usage: 90.6+ KB\n",
      "... Processing\n",
      "Init train MNB\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=  58.8s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   1.5s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.0s\n",
      "End train MNB\n",
      "Save/load model category_MNB\n",
      "accuracy_test:   0.837\n",
      "accuracy_eval:   0.836\n",
      "classification report:\n",
      "TEST\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "   exploration       0.94      0.84      0.89        56\n",
      "   headhunters       0.65      0.98      0.78        51\n",
      "  intelligence       0.95      0.43      0.59        42\n",
      "     logistics       0.96      0.88      0.91        49\n",
      "      politics       0.74      0.96      0.84        57\n",
      "transportation       0.89      0.87      0.88        68\n",
      "       weapons       0.94      0.81      0.87        58\n",
      "\n",
      "      accuracy                           0.84       381\n",
      "     macro avg       0.87      0.82      0.82       381\n",
      "  weighted avg       0.87      0.84      0.83       381\n",
      "\n",
      "EVAL\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "   exploration       0.94      0.92      0.93        73\n",
      "   headhunters       0.65      1.00      0.79        48\n",
      "  intelligence       1.00      0.43      0.60        49\n",
      "     logistics       0.98      0.76      0.86        55\n",
      "      politics       0.76      0.95      0.84        60\n",
      "transportation       0.82      0.94      0.88        50\n",
      "       weapons       0.90      0.80      0.85        56\n",
      "\n",
      "      accuracy                           0.84       391\n",
      "     macro avg       0.86      0.83      0.82       391\n",
      "  weighted avg       0.87      0.84      0.83       391\n",
      "\n",
      "confusion matrix:\n",
      "TEST\n",
      " [[47  6  1  0  1  1  0]\n",
      " [ 0 50  0  0  1  0  0]\n",
      " [ 2  5 18  1 10  4  2]\n",
      " [ 1  4  0 43  1  0  0]\n",
      " [ 0  2  0  0 55  0  0]\n",
      " [ 0  6  0  0  2 59  1]\n",
      " [ 0  4  0  1  4  2 47]]\n",
      "EVAL\n",
      " [[67  6  0  0  0  0  0]\n",
      " [ 0 48  0  0  0  0  0]\n",
      " [ 1  6 21  1 11  4  5]\n",
      " [ 2  6  0 42  4  1  0]\n",
      " [ 0  1  0  0 57  2  0]\n",
      " [ 0  3  0  0  0 47  0]\n",
      " [ 1  4  0  0  3  3 45]]\n",
      "... Processing\n",
      "Init train SVC\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=  58.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   1.5s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.2s\n",
      "End train SVC\n",
      "Save/load model category_SVC\n",
      "accuracy_test:   0.934\n",
      "accuracy_eval:   0.890\n",
      "classification report:\n",
      "TEST\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "   exploration       1.00      0.96      0.98        56\n",
      "   headhunters       0.85      0.98      0.91        51\n",
      "  intelligence       1.00      0.79      0.88        42\n",
      "     logistics       0.98      0.96      0.97        49\n",
      "      politics       0.88      0.98      0.93        57\n",
      "transportation       0.91      0.93      0.92        68\n",
      "       weapons       0.98      0.91      0.95        58\n",
      "\n",
      "      accuracy                           0.93       381\n",
      "     macro avg       0.94      0.93      0.93       381\n",
      "  weighted avg       0.94      0.93      0.93       381\n",
      "\n",
      "EVAL\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "   exploration       0.96      0.89      0.92        73\n",
      "   headhunters       0.83      1.00      0.91        48\n",
      "  intelligence       1.00      0.65      0.79        49\n",
      "     logistics       0.95      0.95      0.95        55\n",
      "      politics       0.84      0.97      0.90        60\n",
      "transportation       0.81      0.96      0.88        50\n",
      "       weapons       0.90      0.80      0.85        56\n",
      "\n",
      "      accuracy                           0.89       391\n",
      "     macro avg       0.90      0.89      0.88       391\n",
      "  weighted avg       0.90      0.89      0.89       391\n",
      "\n",
      "confusion matrix:\n",
      "TEST\n",
      " [[54  1  0  0  1  0  0]\n",
      " [ 0 50  0  0  1  0  0]\n",
      " [ 0  2 33  1  2  4  0]\n",
      " [ 0  2  0 47  0  0  0]\n",
      " [ 0  1  0  0 56  0  0]\n",
      " [ 0  2  0  0  2 63  1]\n",
      " [ 0  1  0  0  2  2 53]]\n",
      "EVAL\n",
      " [[65  4  0  0  3  1  0]\n",
      " [ 0 48  0  0  0  0  0]\n",
      " [ 0  1 32  3  4  4  5]\n",
      " [ 1  1  0 52  1  0  0]\n",
      " [ 0  0  0  0 58  2  0]\n",
      " [ 0  1  0  0  1 48  0]\n",
      " [ 2  3  0  0  2  4 45]]\n",
      "... Processing\n",
      "Init train LogReg\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=  57.9s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   1.5s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.3s\n",
      "End train LogReg\n",
      "Save/load model category_LogReg\n",
      "accuracy_test:   0.866\n",
      "accuracy_eval:   0.847\n",
      "classification report:\n",
      "TEST\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "   exploration       0.96      0.88      0.92        56\n",
      "   headhunters       0.66      0.98      0.79        51\n",
      "  intelligence       0.96      0.60      0.74        42\n",
      "     logistics       0.98      0.88      0.92        49\n",
      "      politics       0.85      0.96      0.90        57\n",
      "transportation       0.87      0.90      0.88        68\n",
      "       weapons       0.96      0.81      0.88        58\n",
      "\n",
      "      accuracy                           0.87       381\n",
      "     macro avg       0.89      0.86      0.86       381\n",
      "  weighted avg       0.89      0.87      0.87       381\n",
      "\n",
      "EVAL\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "   exploration       0.94      0.90      0.92        73\n",
      "   headhunters       0.66      1.00      0.79        48\n",
      "  intelligence       1.00      0.49      0.66        49\n",
      "     logistics       0.98      0.85      0.91        55\n",
      "      politics       0.83      0.95      0.88        60\n",
      "transportation       0.78      0.94      0.85        50\n",
      "       weapons       0.89      0.75      0.82        56\n",
      "\n",
      "      accuracy                           0.85       391\n",
      "     macro avg       0.87      0.84      0.83       391\n",
      "  weighted avg       0.87      0.85      0.84       391\n",
      "\n",
      "confusion matrix:\n",
      "TEST\n",
      " [[49  4  1  0  2  0  0]\n",
      " [ 0 50  0  0  1  0  0]\n",
      " [ 1  6 25  1  3  5  1]\n",
      " [ 1  3  0 43  1  1  0]\n",
      " [ 0  2  0  0 55  0  0]\n",
      " [ 0  5  0  0  1 61  1]\n",
      " [ 0  6  0  0  2  3 47]]\n",
      "EVAL\n",
      " [[66  5  0  0  1  1  0]\n",
      " [ 0 48  0  0  0  0  0]\n",
      " [ 1  4 24  1  8  6  5]\n",
      " [ 1  6  0 47  1  0  0]\n",
      " [ 0  2  0  0 57  1  0]\n",
      " [ 0  3  0  0  0 47  0]\n",
      " [ 2  5  0  0  2  5 42]]\n",
      "... Processing\n",
      "Init train XGB\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=  57.7s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   1.5s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=  11.7s\n",
      "End train XGB\n",
      "Save/load model category_XGB\n",
      "accuracy_test:   0.738\n",
      "accuracy_eval:   0.701\n",
      "classification report:\n",
      "TEST\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "   exploration       0.78      0.68      0.72        56\n",
      "   headhunters       0.61      0.90      0.73        51\n",
      "  intelligence       0.62      0.50      0.55        42\n",
      "     logistics       0.88      0.76      0.81        49\n",
      "      politics       0.88      0.86      0.87        57\n",
      "transportation       0.70      0.74      0.72        68\n",
      "       weapons       0.74      0.69      0.71        58\n",
      "\n",
      "      accuracy                           0.74       381\n",
      "     macro avg       0.74      0.73      0.73       381\n",
      "  weighted avg       0.75      0.74      0.74       381\n",
      "\n",
      "EVAL\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "   exploration       0.77      0.66      0.71        73\n",
      "   headhunters       0.66      0.83      0.73        48\n",
      "  intelligence       0.46      0.35      0.40        49\n",
      "     logistics       0.84      0.67      0.75        55\n",
      "      politics       0.81      0.92      0.86        60\n",
      "transportation       0.59      0.80      0.68        50\n",
      "       weapons       0.73      0.66      0.69        56\n",
      "\n",
      "      accuracy                           0.70       391\n",
      "     macro avg       0.69      0.70      0.69       391\n",
      "  weighted avg       0.70      0.70      0.70       391\n",
      "\n",
      "confusion matrix:\n",
      "TEST\n",
      " [[38  9  1  0  1  5  2]\n",
      " [ 2 46  0  0  0  3  0]\n",
      " [ 3  1 21  2  3  6  6]\n",
      " [ 1  6  2 37  0  1  2]\n",
      " [ 1  3  1  1 49  1  1]\n",
      " [ 2  7  2  2  2 50  3]\n",
      " [ 2  3  7  0  1  5 40]]\n",
      "EVAL\n",
      " [[48  5  4  2  6  4  4]\n",
      " [ 3 40  0  0  0  4  1]\n",
      " [ 3  5 17  3  3 10  8]\n",
      " [ 4  3  4 37  2  4  1]\n",
      " [ 1  2  1  0 55  1  0]\n",
      " [ 2  4  2  1  1 40  0]\n",
      " [ 1  2  9  1  1  5 37]]\n",
      "... Processing\n",
      "Init train RFC\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=  58.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   1.5s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   1.2s\n",
      "End train RFC\n",
      "Save/load model category_RFC\n",
      "accuracy_test:   0.722\n",
      "accuracy_eval:   0.693\n",
      "classification report:\n",
      "TEST\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "   exploration       0.91      0.70      0.79        56\n",
      "   headhunters       0.42      0.92      0.58        51\n",
      "  intelligence       0.78      0.43      0.55        42\n",
      "     logistics       0.88      0.76      0.81        49\n",
      "      politics       0.82      0.93      0.87        57\n",
      "transportation       0.84      0.72      0.78        68\n",
      "       weapons       0.82      0.55      0.66        58\n",
      "\n",
      "      accuracy                           0.72       381\n",
      "     macro avg       0.78      0.71      0.72       381\n",
      "  weighted avg       0.79      0.72      0.73       381\n",
      "\n",
      "EVAL\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "   exploration       0.81      0.68      0.74        73\n",
      "   headhunters       0.44      0.94      0.60        48\n",
      "  intelligence       0.72      0.37      0.49        49\n",
      "     logistics       0.87      0.62      0.72        55\n",
      "      politics       0.80      0.93      0.86        60\n",
      "transportation       0.68      0.80      0.73        50\n",
      "       weapons       0.85      0.50      0.63        56\n",
      "\n",
      "      accuracy                           0.69       391\n",
      "     macro avg       0.74      0.69      0.68       391\n",
      "  weighted avg       0.75      0.69      0.69       391\n",
      "\n",
      "confusion matrix:\n",
      "TEST\n",
      " [[39 11  1  1  1  2  1]\n",
      " [ 1 47  0  0  1  2  0]\n",
      " [ 0 12 18  0  5  3  4]\n",
      " [ 2  9  0 37  0  0  1]\n",
      " [ 0  3  0  1 53  0  0]\n",
      " [ 1 12  1  1  3 49  1]\n",
      " [ 0 17  3  2  2  2 32]]\n",
      "EVAL\n",
      " [[50 15  1  1  3  2  1]\n",
      " [ 2 45  0  0  1  0  0]\n",
      " [ 4 11 18  2  4  6  4]\n",
      " [ 4  9  2 34  2  4  0]\n",
      " [ 1  3  0  0 56  0  0]\n",
      " [ 1  6  2  0  1 40  0]\n",
      " [ 0 14  2  2  3  7 28]]\n",
      "... Processing\n",
      "Init train KNN\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=  57.5s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   1.4s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.0s\n",
      "End train KNN\n",
      "Save/load model category_KNN\n",
      "accuracy_test:   0.782\n",
      "accuracy_eval:   0.780\n",
      "classification report:\n",
      "TEST\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "   exploration       0.93      0.75      0.83        56\n",
      "   headhunters       0.47      0.96      0.63        51\n",
      "  intelligence       0.89      0.57      0.70        42\n",
      "     logistics       0.98      0.86      0.91        49\n",
      "      politics       0.78      0.91      0.84        57\n",
      "transportation       0.92      0.71      0.80        68\n",
      "       weapons       0.98      0.71      0.82        58\n",
      "\n",
      "      accuracy                           0.78       381\n",
      "     macro avg       0.85      0.78      0.79       381\n",
      "  weighted avg       0.85      0.78      0.79       381\n",
      "\n",
      "EVAL\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "   exploration       1.00      0.77      0.87        73\n",
      "   headhunters       0.47      1.00      0.64        48\n",
      "  intelligence       1.00      0.59      0.74        49\n",
      "     logistics       0.96      0.82      0.88        55\n",
      "      politics       0.77      0.88      0.82        60\n",
      "transportation       0.80      0.74      0.77        50\n",
      "       weapons       0.88      0.66      0.76        56\n",
      "\n",
      "      accuracy                           0.78       391\n",
      "     macro avg       0.84      0.78      0.78       391\n",
      "  weighted avg       0.85      0.78      0.79       391\n",
      "\n",
      "confusion matrix:\n",
      "TEST\n",
      " [[42 12  1  0  1  0  0]\n",
      " [ 1 49  0  0  1  0  0]\n",
      " [ 0 10 24  1  5  2  0]\n",
      " [ 0  7  0 42  0  0  0]\n",
      " [ 0  4  1  0 52  0  0]\n",
      " [ 1 15  0  0  3 48  1]\n",
      " [ 1  8  1  0  5  2 41]]\n",
      "EVAL\n",
      " [[56 11  0  0  2  3  1]\n",
      " [ 0 48  0  0  0  0  0]\n",
      " [ 0  8 29  1  8  1  2]\n",
      " [ 0  8  0 45  0  0  2]\n",
      " [ 0  6  0  0 53  1  0]\n",
      " [ 0 10  0  1  2 37  0]\n",
      " [ 0 11  0  0  4  4 37]]\n"
     ]
    }
   ],
   "source": [
    "!python3 train.py \"dataset\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con **Linear SVC**, llegamos a **93%** de accuracy en test (0.934) [en eval, 0.89, lo que nos da un mean de 0.912], o acierto 1 a 1, true_predict=true_label, siendo la categoría mejor clasificada *exploration* y la peor, *intelligence*, esto según su F1-score, que es una métrica de la media armónica calculada a partir de precision (¿Qué proporción de identificaciones positivas fue realmente correcta?) y recall (¿Qué proporción de positivos reales se identificó correctamente?). Esto último, se repite para todos los demás clasificadores, excepto para KNN (peor: *headhunters* y el segundo peor: *intelligence*)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos explorar mientras la categoría, intelligence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "345    b'n <C50sJG.3Eu@voder.nsc.com> matt@galaxy.nsc.com (Matt Freivald x8043) writes:\\n\\n>In article 164633 in talk.politics.misc, bob1@cos.com (Bob Blackshaw) writes:\\n\\n>>>>And Ms. Regard, please don\\'t give us the trite \"you can\\'t legislate \\n>>>>morality\" nonsense again: there is little else that is legislated, \\n>>>>including the moral concept of \"rights\".\\n\\n>>Really? Pure Socialism had this belief, and fell flat on its ass by\\n>>attempting to follow such reasoning. Suppose you pass a law that\\n>>states that I must love my neighbour, regardless of race, religion,\\n>>etc. How exactly do you plan to enforce such a law? Better yet, how\\n>>do you plan to measure compliance? And even if you overcome those\\n>>two obstacles, how will you ever know if I have become *more moral*\\n>>or not?\\n\\n>You either missed the point or are being somewhat disingenuous;  I have\\n>never heard anyone suggest that you can legislate what people think.\\n>Laws are based on either expediency (i.e. traffic laws) or morality (i.e.\\n>human rights), as far as I can tell, and the majority are based on the\\n>latter.\\n\\nOnce more around the racetrack. See the original statement that it is\\nnonsense to believe that you cannot legislate morality. I simply stated\\nthat they can pass all the laws they want but not a single one of them\\nwill make you or I more moral people. They may make us act in a moral\\nmanner, but our actions are only a reflection of the unwillingness to\\nrisk punishment. They say nothing about whether we have become more\\nmoral or not. Perhaps the distinction is too fine.\\n\\n\\n\\n>Matt Freivald\\n\\nTOG\\n\\n>--------------------------------------------------------------------------\\n>               \"I\\'m not a feminist -- I\\'m for equal rights!\"\\n>--------------------------------------------------------------------------\\n>             If you don\\'t believe in abortion, don\\'t have one!\\n>              If you don\\'t believe in slavery, don\\'t own one!\\n>             If you don\\'t believe in murder, don\\'t commit one!\\n>--------------------------------------------------------------------------\\n>                   Pro CHILD. Pro FAMILY. Pro LIFE.\\n>--------------------------------------------------------------------------\\n>THESE ARE MY OPINIONS ONLY AND NOT THOSE OF MY EMPLOYER!!!!!!!!!!!!!!!!!!!\\n>--------------------------------------------------------------------------'\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mydf[mydf.category=='intelligence']['text'].sample(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1292    b'ticle-I.D.: news.C51rzx.AC3\\n\\nnsmca@aurora.alaska.edu writes:\\n\\n[Excellent discussion of DC-X landing techniques by Henry deleted]\\n\\n>Since the DC-X is to take off horizontal, why not land that way??\\n\\nThe DC-X will not take of horizontally.  It takes of vertically. \\n\\n>Why do the Martian Landing thing.. \\n\\nFor several reasons.  Vertical landings don\\'t require miles of runway and limit\\nnoise pollution.  They don\\'t require wheels or wings.  Just turn on the engines\\nand touch down.  Of course, as Henry pointed out, vetical landings aren\\'t quite\\nthat simple.\\n\\n>Or am I missing something.. Don\\'t know to\\n>much about DC-X and such.. (overly obvious?).\\n\\nWell, to be blunt, yes.  But at least you\\'re learning.\\n\\n>Why not just fall to earth like the russian crafts?? Parachute in then...\\n\\nThe Soyuz vehicles use parachutes for the descent and then fire small rockets\\njust before they hit the ground.  Parachutes are, however, not especially\\npractical if you want to reuse something without much effort.  The landings\\nare also not very comfortable.  However, in the words of Georgy Grechko,\\n\"I prefer to have bruises, not to sink.\"\\n\\n\\n-- \\nJosh Hopkins                                          jbh55289@uxa.cso.uiuc.edu\\n          \"Tout ce qu\\'un homme est capable d\\'imaginer, d\\'autres hommes\\n            \\t     seront capable de la realiser\"\\n\\t\\t\\t -Jules Verne'\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mydf[mydf.category=='exploration']['text'].sample(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparando con exploration, parecen ser textos más largos de media, comprobemos..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydf['text_length'] = mydf.text.apply(lambda a: len(a))\n",
    "mydf['text_token_count'] = mydf.text.apply(lambda a: len(a.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2646.2903225806454, 422.73333333333335)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mydf[mydf.category=='intelligence']['text_length'].mean(),mydf[mydf.category=='intelligence']['text_token_count'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1789.3490725126476, 273.5615514333895)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mydf[mydf.category=='exploration']['text_length'].mean(),mydf[mydf.category=='exploration']['text_token_count'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que si... a lo mejor con rich text mining el texto...mejora"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experimento 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Pipeline_:\n",
    "\n",
    "`pipeline[name] = Pipeline([\n",
    "                ('vect', CountVectorizer(stop_words=stop_words,preprocessor=clean_text)), # clean_text extended: only words, lemma, content words\n",
    "                ('tfidf', TfidfVectorizer()),\n",
    "                ('clf', model),\n",
    "            ], verbose=1)`\n",
    "            \n",
    "_Models params_:\n",
    "\n",
    "`models = {\"MNB\": MultinomialNB(fit_prior=True, class_prior=None),\n",
    "          \"SVC\":LinearSVC(),\n",
    "          \"LogReg\":LogisticRegression(solver='sag',n_jobs=-1),\n",
    "          \"XGB\":XGBClassifier(n_jobs=-1,eval_metric='merror'),\n",
    "          \"RFC\":RandomForestClassifier(n_jobs=-1),\n",
    "          \"KNN\":KNeighborsClassifier(n_neighbors=10,n_jobs=-1)} # slow, use 10 neighbors`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3859 entries, 0 to 3858\n",
      "Data columns (total 3 columns):\n",
      "id          3859 non-null object\n",
      "category    3859 non-null object\n",
      "text        3859 non-null object\n",
      "dtypes: object(3)\n",
      "memory usage: 90.6+ KB\n",
      "... Processing\n",
      "Init train MNB\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=  28.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   1.3s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.0s\n",
      "End train MNB\n",
      "Save/load model category_MNB\n",
      "accuracy_test:   0.893\n",
      "accuracy_eval:   0.887\n",
      "classification report:\n",
      "TEST\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "   exploration       0.98      0.92      0.95        64\n",
      "   headhunters       0.79      0.98      0.88        51\n",
      "  intelligence       1.00      0.50      0.67        44\n",
      "     logistics       0.94      0.88      0.91        51\n",
      "      politics       0.91      0.96      0.94        54\n",
      "transportation       0.88      0.95      0.91        62\n",
      "       weapons       0.84      0.95      0.89        66\n",
      "\n",
      "      accuracy                           0.89       392\n",
      "     macro avg       0.91      0.88      0.88       392\n",
      "  weighted avg       0.90      0.89      0.89       392\n",
      "\n",
      "EVAL\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "   exploration       0.93      0.97      0.95        65\n",
      "   headhunters       0.77      1.00      0.87        48\n",
      "  intelligence       1.00      0.60      0.75        47\n",
      "     logistics       0.94      0.83      0.88        53\n",
      "      politics       0.95      0.94      0.94        63\n",
      "transportation       0.91      0.91      0.91        56\n",
      "       weapons       0.77      0.92      0.84        48\n",
      "\n",
      "      accuracy                           0.89       380\n",
      "     macro avg       0.90      0.88      0.88       380\n",
      "  weighted avg       0.90      0.89      0.88       380\n",
      "\n",
      "confusion matrix:\n",
      "TEST\n",
      " [[59  5  0  0  0  0  0]\n",
      " [ 0 50  0  0  0  1  0]\n",
      " [ 0  3 22  2  3  3 11]\n",
      " [ 1  1  0 45  1  2  1]\n",
      " [ 0  1  0  0 52  1  0]\n",
      " [ 0  3  0  0  0 59  0]\n",
      " [ 0  0  0  1  1  1 63]]\n",
      "EVAL\n",
      " [[63  1  0  0  1  0  0]\n",
      " [ 0 48  0  0  0  0  0]\n",
      " [ 2  2 28  1  1  2 11]\n",
      " [ 2  4  0 44  1  1  1]\n",
      " [ 1  2  0  0 59  1  0]\n",
      " [ 0  4  0  0  0 51  1]\n",
      " [ 0  1  0  2  0  1 44]]\n",
      "... Processing\n",
      "Init train SVC\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=  28.0s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   1.3s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.1s\n",
      "End train SVC\n",
      "Save/load model category_SVC\n",
      "accuracy_test:   0.929\n",
      "accuracy_eval:   0.924\n",
      "classification report:\n",
      "TEST\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "   exploration       0.98      0.88      0.93        64\n",
      "   headhunters       0.86      1.00      0.93        51\n",
      "  intelligence       0.89      0.77      0.83        44\n",
      "     logistics       0.94      0.98      0.96        51\n",
      "      politics       0.96      0.98      0.97        54\n",
      "transportation       0.94      0.97      0.95        62\n",
      "       weapons       0.91      0.91      0.91        66\n",
      "\n",
      "      accuracy                           0.93       392\n",
      "     macro avg       0.93      0.93      0.93       392\n",
      "  weighted avg       0.93      0.93      0.93       392\n",
      "\n",
      "EVAL\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "   exploration       0.94      0.95      0.95        65\n",
      "   headhunters       0.87      1.00      0.93        48\n",
      "  intelligence       0.93      0.81      0.86        47\n",
      "     logistics       0.92      0.91      0.91        53\n",
      "      politics       0.98      0.95      0.97        63\n",
      "transportation       0.91      0.93      0.92        56\n",
      "       weapons       0.90      0.90      0.90        48\n",
      "\n",
      "      accuracy                           0.92       380\n",
      "     macro avg       0.92      0.92      0.92       380\n",
      "  weighted avg       0.92      0.92      0.92       380\n",
      "\n",
      "confusion matrix:\n",
      "TEST\n",
      " [[56  6  0  0  1  0  1]\n",
      " [ 0 51  0  0  0  0  0]\n",
      " [ 0  2 34  1  0  2  5]\n",
      " [ 1  0  0 50  0  0  0]\n",
      " [ 0  0  1  0 53  0  0]\n",
      " [ 0  0  1  0  1 60  0]\n",
      " [ 0  0  2  2  0  2 60]]\n",
      "EVAL\n",
      " [[62  2  0  0  0  1  0]\n",
      " [ 0 48  0  0  0  0  0]\n",
      " [ 0  0 38  2  0  3  4]\n",
      " [ 3  1  0 48  1  0  0]\n",
      " [ 1  2  0  0 60  0  0]\n",
      " [ 0  2  1  0  0 52  1]\n",
      " [ 0  0  2  2  0  1 43]]\n",
      "... Processing\n",
      "Init train LogReg\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=  27.6s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   1.3s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.2s\n",
      "End train LogReg\n",
      "Save/load model category_LogReg\n",
      "accuracy_test:   0.903\n",
      "accuracy_eval:   0.911\n",
      "classification report:\n",
      "TEST\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "   exploration       0.98      0.88      0.93        64\n",
      "   headhunters       0.76      0.98      0.85        51\n",
      "  intelligence       0.93      0.64      0.76        44\n",
      "     logistics       0.96      0.94      0.95        51\n",
      "      politics       0.93      0.94      0.94        54\n",
      "transportation       0.92      0.98      0.95        62\n",
      "       weapons       0.88      0.91      0.90        66\n",
      "\n",
      "      accuracy                           0.90       392\n",
      "     macro avg       0.91      0.90      0.90       392\n",
      "  weighted avg       0.91      0.90      0.90       392\n",
      "\n",
      "EVAL\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "   exploration       0.93      0.97      0.95        65\n",
      "   headhunters       0.83      1.00      0.91        48\n",
      "  intelligence       0.93      0.79      0.85        47\n",
      "     logistics       0.92      0.87      0.89        53\n",
      "      politics       0.97      0.94      0.95        63\n",
      "transportation       0.89      0.91      0.90        56\n",
      "       weapons       0.91      0.88      0.89        48\n",
      "\n",
      "      accuracy                           0.91       380\n",
      "     macro avg       0.91      0.91      0.91       380\n",
      "  weighted avg       0.91      0.91      0.91       380\n",
      "\n",
      "confusion matrix:\n",
      "TEST\n",
      " [[56  6  1  0  1  0  0]\n",
      " [ 0 50  0  0  0  1  0]\n",
      " [ 0  4 28  1  1  2  8]\n",
      " [ 1  0  0 48  1  1  0]\n",
      " [ 0  2  1  0 51  0  0]\n",
      " [ 0  1  0  0  0 61  0]\n",
      " [ 0  3  0  1  1  1 60]]\n",
      "EVAL\n",
      " [[63  1  0  0  0  1  0]\n",
      " [ 0 48  0  0  0  0  0]\n",
      " [ 1  1 37  2  1  2  3]\n",
      " [ 3  3  0 46  1  0  0]\n",
      " [ 1  2  0  0 59  1  0]\n",
      " [ 0  3  1  0  0 51  1]\n",
      " [ 0  0  2  2  0  2 42]]\n",
      "... Processing\n",
      "Init train XGB\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=  27.7s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   1.3s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   8.0s\n",
      "End train XGB\n",
      "Save/load model category_XGB\n",
      "accuracy_test:   0.770\n",
      "accuracy_eval:   0.779\n",
      "classification report:\n",
      "TEST\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "   exploration       0.80      0.69      0.74        64\n",
      "   headhunters       0.64      0.90      0.75        51\n",
      "  intelligence       0.70      0.64      0.67        44\n",
      "     logistics       0.85      0.76      0.80        51\n",
      "      politics       0.83      0.91      0.87        54\n",
      "transportation       0.82      0.81      0.81        62\n",
      "       weapons       0.78      0.70      0.74        66\n",
      "\n",
      "      accuracy                           0.77       392\n",
      "     macro avg       0.77      0.77      0.77       392\n",
      "  weighted avg       0.78      0.77      0.77       392\n",
      "\n",
      "EVAL\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "   exploration       0.83      0.82      0.82        65\n",
      "   headhunters       0.66      0.83      0.73        48\n",
      "  intelligence       0.83      0.64      0.72        47\n",
      "     logistics       0.85      0.77      0.81        53\n",
      "      politics       0.83      0.90      0.86        63\n",
      "transportation       0.78      0.75      0.76        56\n",
      "       weapons       0.69      0.69      0.69        48\n",
      "\n",
      "      accuracy                           0.78       380\n",
      "     macro avg       0.78      0.77      0.77       380\n",
      "  weighted avg       0.79      0.78      0.78       380\n",
      "\n",
      "confusion matrix:\n",
      "TEST\n",
      " [[44  6  3  2  4  3  2]\n",
      " [ 1 46  0  1  0  2  1]\n",
      " [ 2  2 28  1  3  1  7]\n",
      " [ 2  4  2 39  1  2  1]\n",
      " [ 1  3  1  0 49  0  0]\n",
      " [ 3  6  0  0  1 50  2]\n",
      " [ 2  5  6  3  1  3 46]]\n",
      "EVAL\n",
      " [[53  4  0  0  4  2  2]\n",
      " [ 3 40  1  1  1  2  0]\n",
      " [ 3  1 30  4  1  3  5]\n",
      " [ 0  5  0 41  3  0  4]\n",
      " [ 2  3  0  0 57  0  1]\n",
      " [ 1  6  0  2  2 42  3]\n",
      " [ 2  2  5  0  1  5 33]]\n",
      "... Processing\n",
      "Init train RFC\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=  27.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   1.3s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.9s\n",
      "End train RFC\n",
      "Save/load model category_RFC\n",
      "accuracy_test:   0.804\n",
      "accuracy_eval:   0.826\n",
      "classification report:\n",
      "TEST\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "   exploration       0.90      0.70      0.79        64\n",
      "   headhunters       0.58      0.92      0.71        51\n",
      "  intelligence       0.86      0.57      0.68        44\n",
      "     logistics       0.91      0.82      0.87        51\n",
      "      politics       0.71      0.96      0.82        54\n",
      "transportation       0.89      0.89      0.89        62\n",
      "       weapons       0.96      0.74      0.84        66\n",
      "\n",
      "      accuracy                           0.80       392\n",
      "     macro avg       0.83      0.80      0.80       392\n",
      "  weighted avg       0.84      0.80      0.81       392\n",
      "\n",
      "EVAL\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "   exploration       0.88      0.80      0.84        65\n",
      "   headhunters       0.64      0.92      0.75        48\n",
      "  intelligence       0.82      0.70      0.76        47\n",
      "     logistics       0.93      0.81      0.87        53\n",
      "      politics       0.86      0.94      0.89        63\n",
      "transportation       0.83      0.86      0.84        56\n",
      "       weapons       0.90      0.73      0.80        48\n",
      "\n",
      "      accuracy                           0.83       380\n",
      "     macro avg       0.84      0.82      0.82       380\n",
      "  weighted avg       0.84      0.83      0.83       380\n",
      "\n",
      "confusion matrix:\n",
      "TEST\n",
      " [[45 11  0  1  7  0  0]\n",
      " [ 0 47  0  0  2  2  0]\n",
      " [ 1  7 25  1  5  3  2]\n",
      " [ 1  4  0 42  3  1  0]\n",
      " [ 1  1  0  0 52  0  0]\n",
      " [ 0  6  0  0  1 55  0]\n",
      " [ 2  5  4  2  3  1 49]]\n",
      "EVAL\n",
      " [[52  7  1  0  3  2  0]\n",
      " [ 2 44  1  0  0  1  0]\n",
      " [ 1  4 33  2  2  2  3]\n",
      " [ 1  3  2 43  3  0  1]\n",
      " [ 2  2  0  0 59  0  0]\n",
      " [ 1  6  1  0  0 48  0]\n",
      " [ 0  3  2  1  2  5 35]]\n",
      "... Processing\n",
      "Init train KNN\n",
      "[Pipeline] .............. (step 1 of 3) Processing vect, total=  28.3s\n",
      "[Pipeline] ............. (step 2 of 3) Processing tfidf, total=   1.3s\n",
      "[Pipeline] ............... (step 3 of 3) Processing clf, total=   0.0s\n",
      "End train KNN\n",
      "Save/load model category_KNN\n",
      "accuracy_test:   0.171\n",
      "accuracy_eval:   0.153\n",
      "classification report:\n",
      "TEST\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "   exploration       1.00      0.08      0.14        64\n",
      "   headhunters       0.14      1.00      0.24        51\n",
      "  intelligence       1.00      0.02      0.04        44\n",
      "     logistics       0.00      0.00      0.00        51\n",
      "      politics       1.00      0.09      0.17        54\n",
      "transportation       1.00      0.03      0.06        62\n",
      "       weapons       1.00      0.05      0.09        66\n",
      "\n",
      "      accuracy                           0.17       392\n",
      "     macro avg       0.73      0.18      0.11       392\n",
      "  weighted avg       0.76      0.17      0.11       392\n",
      "\n",
      "EVAL\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "   exploration       1.00      0.03      0.06        65\n",
      "   headhunters       0.13      1.00      0.23        48\n",
      "  intelligence       0.00      0.00      0.00        47\n",
      "     logistics       0.00      0.00      0.00        53\n",
      "      politics       1.00      0.08      0.15        63\n",
      "transportation       1.00      0.02      0.04        56\n",
      "       weapons       1.00      0.04      0.08        48\n",
      "\n",
      "      accuracy                           0.15       380\n",
      "     macro avg       0.59      0.17      0.08       380\n",
      "  weighted avg       0.63      0.15      0.08       380\n",
      "\n",
      "confusion matrix:\n",
      "TEST\n",
      " [[ 5 59  0  0  0  0  0]\n",
      " [ 0 51  0  0  0  0  0]\n",
      " [ 0 43  1  0  0  0  0]\n",
      " [ 0 51  0  0  0  0  0]\n",
      " [ 0 49  0  0  5  0  0]\n",
      " [ 0 60  0  0  0  2  0]\n",
      " [ 0 63  0  0  0  0  3]]\n",
      "EVAL\n",
      " [[ 2 63  0  0  0  0  0]\n",
      " [ 0 48  0  0  0  0  0]\n",
      " [ 0 47  0  0  0  0  0]\n",
      " [ 0 53  0  0  0  0  0]\n",
      " [ 0 58  0  0  5  0  0]\n",
      " [ 0 55  0  0  0  1  0]\n",
      " [ 0 46  0  0  0  0  2]]\n"
     ]
    }
   ],
   "source": [
    "!python3 train.py \"dataset\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bien, con rich text mining, conseguimos subir las metrics, pero no subir la de la categoría *intelligence* (F1-Score) en el mejor modelo **Linear SVC**, pero en las demás, si. Lo que prueba un poco la teoría. Conseguimos un accuracy en test y eval del **0.9265** para el mejor modelo, con metrics bastante equilibradas en su avg.\n",
    "\n",
    "Un párrafo aparte, necesita el KNN, se ve que el rich text mining lo tiró al piso, cuando presentaba el modelo hablaba de los vecinos, pero al hacer un clean text casi extremo, quedaron muy singulares (sin vecinos?)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como baseline, está muy bien, quizá con estos modelos se podrían probar más cosas: trabajando abreviaturas? o ir jugando con las combinaciones del clean_text function, haciendo cutt-off del vectorizer...haciendo gridsearch para encontrar el mejor modelo...también probar k-fold... incluso SMOTE para esas clases, con pocas muestras (e.g., *intelligence*)\n",
    "\n",
    "Lo siguiente sería escalar a Deep Learning: CNN, LSTM...o sus combinaciones...o bien, transformers, BERT por ejemplo, incluso haciendo fine-tuning (aunque ya se necesita otra capacidad de cómputo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dataset/logistics/51131',\n",
       " 'dataset/weapons/54387',\n",
       " 'dataset/intelligence/178521']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read files\n",
    "import glob\n",
    "import random\n",
    "#\n",
    "files = glob.glob(\"{}/*/*{}\".format(\"dataset\",\"\"))\n",
    "sample = random.sample(files, 3)\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/logistics/51131 logistics \n",
      "dataset/weapons/54387 weapons \n",
      "dataset/intelligence/178521 intelligence \n"
     ]
    }
   ],
   "source": [
    "!python3 classify.py \"models/category_SVC.joblib\" 'dataset/logistics/51131' 'dataset/weapons/54387' 'dataset/intelligence/178521'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizamos el mejor modelo, del experimento 2. Sus metrics son:\n",
    "\n",
    "_test_\n",
    "\n",
    "`(metric, precision, recall, f1-score, support)\n",
    "accuracy                            0.93       392\n",
    "macro avg       0.93      0.93      0.93       392\n",
    "weighted avg    0.93      0.93      0.93       392`\n",
    "\n",
    "_eval_\n",
    "\n",
    "`(metric, precision, recall, f1-score, support)\n",
    "accuracy                            0.92       380\n",
    "macro avg       0.92      0.92      0.92       380\n",
    "weighted avg    0.92      0.92      0.92       380`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*La misión es conseguir que el sistema de clasificación sea capaz de clasificar una\n",
    "nueva transmisión de manera automática para que el departamento de operaciones pueda evaluar\n",
    "las amenazas más rápido.* Misión cumplida, pero...\n",
    "\n",
    "entonces a lo mejor al departamento de operaciones le interese evaluar las amenazas en pares de categorías, esto es, sugiriendo, además de la categoría predicha por nuestro clasificador, la segunda con más confidence. Así leyendo rápidamente en una pantalla o panel el mensaje [acá puede haber una tercera misión de text-summarization? ;)], ofreciendo dos posibles códigos, les ayude a decidir dónde se categoriza cada amenaza :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Try it...**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset/logistics/51131 logistics 2nd option: transportation\n",
      "dataset/weapons/54387 weapons 2nd option: exploration\n",
      "dataset/intelligence/178521 intelligence 2nd option: transportation\n"
     ]
    }
   ],
   "source": [
    "!python3 classify.py --pair_code \"models/category_SVC.joblib\" 'dataset/logistics/51131' 'dataset/weapons/54387' 'dataset/intelligence/178521'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-Fin de la transmisión-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python3 train.py \"dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
